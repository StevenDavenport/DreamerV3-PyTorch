# Default configuration for skill-conditioned MBRL

# LLM Configuration
llm:
  provider: "openai"  # or "anthropic"
  model: "gpt-4"
  temperature: 0.7
  max_tokens: 100
  api_key_env: "OPENAI_API_KEY"

# World Model Configuration
world_model:
  latent_dim: 256
  hidden_dim: 512
  num_layers: 3
  learning_rate: 1e-4
  kl_weight: 1.0

# Policy Configuration
policy:
  hidden_dim: 512
  num_layers: 3
  learning_rate: 3e-4
  skill_embedding_dim: 768

# Feasibility Configuration
feasibility:
  hidden_dim: 512
  num_layers: 2
  learning_rate: 1e-4
  num_candidates: 5

# Training Configuration
training:
  batch_size: 32
  buffer_size: 100000
  num_episodes: 1000
  episode_length: 100
  imagination_steps: 50
  update_frequency: 4
  target_update_frequency: 100

# Environment Configuration
environment:
  name: "crafter"
  observation_dim: 64
  action_dim: 17
  render: false

# Logging Configuration
logging:
  log_dir: "./logs"
  wandb_project: "skill-conditioned-mbrl"
  log_frequency: 100
  save_frequency: 1000

# Global settings
seed: 42
device: "cuda"
num_workers: 4 